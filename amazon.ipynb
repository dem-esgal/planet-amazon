{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets first import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, transform, color, exposure, io\n",
    "\n",
    "import scipy\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 420\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Load data\n",
    "train_path = '../input/train-jpg/'\n",
    "test_path = '../input/test-jpg-v2/'\n",
    "train = pd.read_csv('../input/train_v2.csv')\n",
    "test = pd.read_csv('../input/sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function for extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(df, data_path):\n",
    "    im_features = df.copy()\n",
    "\n",
    "    N = len(im_features.image_name.values)\n",
    "\n",
    "    r_mean = np.zeros(N)\n",
    "    g_mean = np.zeros(N)\n",
    "    b_mean = np.zeros(N)\n",
    "    y_mean = np.zeros(N)\n",
    "\n",
    "    r_std = np.zeros(N)\n",
    "    g_std = np.zeros(N)\n",
    "    b_std = np.zeros(N)\n",
    "    y_std = np.zeros(N)\n",
    "\n",
    "    r_max = np.zeros(N)\n",
    "    g_max = np.zeros(N)\n",
    "    b_max = np.zeros(N)\n",
    "    y_max = np.zeros(N)\n",
    "\n",
    "    r_min = np.zeros(N)\n",
    "    g_min = np.zeros(N)\n",
    "    b_min = np.zeros(N)\n",
    "    y_min = np.zeros(N)\n",
    "    \n",
    "    r_kurtosis = np.zeros(N)\n",
    "    g_kurtosis = np.zeros(N)\n",
    "    b_kurtosis = np.zeros(N)\n",
    "    y_kurtosis = np.zeros(N)\n",
    "\n",
    "    r_skewness = np.zeros(N)\n",
    "    g_skewness = np.zeros(N)\n",
    "    b_skewness = np.zeros(N)\n",
    "    y_skewness = np.zeros(N)\n",
    "    \n",
    "    HOG = np.zeros((N,512))\n",
    "\n",
    "    for i, image_name in enumerate(tqdm(im_features.image_name.values, miniters=1000)):\n",
    "        im = io.imread(data_path + image_name + '.jpg')\n",
    "        im = transform.rescale(im, 0.5)\n",
    "        gray = color.rgb2gray(im)\n",
    "        fd = hog(gray, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1),visualise=False,block_norm='L2-Hys')\n",
    "\n",
    "        HOG[i,:] = fd\n",
    "        r = im[:, :, 0].ravel()\n",
    "        g = im[:, :, 1].ravel()\n",
    "        b = im[:, :, 2].ravel()\n",
    "        y = gray.ravel()\n",
    "\n",
    "        r_mean[i] = np.mean(r)\n",
    "        g_mean[i] = np.mean(g)\n",
    "        b_mean[i] = np.mean(b)\n",
    "        y_mean[i] = np.mean(y)\n",
    "        \n",
    "        r_std[i] = np.std(r)\n",
    "        g_std[i] = np.std(g)\n",
    "        b_std[i] = np.std(b)\n",
    "        y_std[i] = np.std(y)\n",
    "\n",
    "        r_max[i] = np.max(r)\n",
    "        g_max[i] = np.max(g)\n",
    "        b_max[i] = np.max(b)\n",
    "        y_max[i] = np.max(y)\n",
    "\n",
    "        r_min[i] = np.min(r)\n",
    "        g_min[i] = np.min(g)\n",
    "        b_min[i] = np.min(b)\n",
    "        y_min[i] = np.min(y)\n",
    "\n",
    "        r_kurtosis[i] = scipy.stats.kurtosis(r)\n",
    "        g_kurtosis[i] = scipy.stats.kurtosis(g)\n",
    "        b_kurtosis[i] = scipy.stats.kurtosis(b)\n",
    "        y_kurtosis[i] = scipy.stats.kurtosis(y)\n",
    "\n",
    "        r_skewness[i] = scipy.stats.skew(r)\n",
    "        g_skewness[i] = scipy.stats.skew(g)\n",
    "        b_skewness[i] = scipy.stats.skew(b)\n",
    "        y_skewness[i] = scipy.stats.skew(y)\n",
    "\n",
    "    im_features['r_mean'] = r_mean\n",
    "    im_features['g_mean'] = g_mean\n",
    "    im_features['b_mean'] = b_mean\n",
    "    im_features['y_mean'] = y_mean\n",
    "\n",
    "    im_features['r_std'] = r_std\n",
    "    im_features['g_std'] = g_std\n",
    "    im_features['b_std'] = b_std\n",
    "    im_features['y_std'] = y_std\n",
    "\n",
    "    im_features['r_max'] = r_max\n",
    "    im_features['g_max'] = g_max\n",
    "    im_features['b_max'] = b_max\n",
    "    im_features['y_max'] = y_max\n",
    "\n",
    "    im_features['r_min'] = r_min\n",
    "    im_features['g_min'] = g_min\n",
    "    im_features['b_min'] = b_min\n",
    "    im_features['y_min'] = y_min\n",
    "\n",
    "\n",
    "    im_features['r_range'] = r_max - r_min\n",
    "    im_features['g_range'] = g_max - g_min\n",
    "    im_features['b_range'] = b_max - b_min\n",
    "    im_features['y_range'] = y_max - y_min\n",
    "\n",
    "    im_features['r_kurtosis'] = r_kurtosis\n",
    "    im_features['g_kurtosis'] = g_kurtosis\n",
    "    im_features['b_kurtosis'] = b_kurtosis\n",
    "    im_features['y_kurtosis'] = y_kurtosis\n",
    "\n",
    "    im_features['r_skewness'] = r_skewness\n",
    "    im_features['g_skewness'] = g_skewness\n",
    "    im_features['b_skewness'] = b_skewness\n",
    "    im_features['y_skewness'] = y_skewness\n",
    "\n",
    "    return im_features, HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40479 [00:00<?, ?it/s]D:\\WinPython\\python-3.5.3.amd64\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "100%|██████████| 40479/40479 [31:39<00:00, 21.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [41:37<00:00, 27.23it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "print('Extracting train features')\n",
    "train_features, train_HOG = extract_features(train, train_path)\n",
    "print('Extracting test features')\n",
    "test_features, test_HOG = extract_features(test, test_path)\n",
    "\n",
    "# Prepare data\n",
    "X = np.array(train_features.drop(['image_name', 'tags'], axis=1))\n",
    "y_train = []\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = np.array(list(set(flatten([l.split(' ') for l in train_features['tags'].values]))))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XH = np.hstack((X, train_HOG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag to classes transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:00<00:00, 256181.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (40479, 28)\n",
      "y.shape = (40479, 17)\n"
     ]
    }
   ],
   "source": [
    "for tags in tqdm(train.tags.values, miniters=1000):\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    y_train.append(targets)\n",
    "\n",
    "y = np.array(y_train, np.uint8)\n",
    "\n",
    "print('X.shape = ' + str(X.shape))\n",
    "print('y.shape = ' + str(y.shape))\n",
    "\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_test = np.array(test_features.drop(['image_name', 'tags'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XHtest = np.hstack((X_test, test_HOG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainand predict with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and making predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [2:42:19<00:00, 543.44s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Train and predict with one-vs-all strategy\n",
    "y_pred = np.zeros((XHtest.shape[0], n_classes))\n",
    "\n",
    "print('Training and making predictions')\n",
    "for class_i in tqdm(range(n_classes), miniters=1):\n",
    "    model = xgb.XGBClassifier(max_depth=4, learning_rate=0.05, n_estimators=1000, \\\n",
    "                              silent=True, objective='binary:logistic', nthread=-1, \\\n",
    "                              gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                              subsample=0.7, colsample_bytree=1, colsample_bylevel=1, \\\n",
    "                              reg_alpha=0, reg_lambda=0, scale_pos_weight=1, \\\n",
    "                              base_score=0.5, seed=random_seed, missing=None)\n",
    "    model.fit(XH, y[:, class_i])\n",
    "    y_pred[:, class_i] = model.predict_proba(XHtest)[:, 1]\n",
    "\n",
    "preds = [' '.join(labels[y_pred_row > 0.21]) for y_pred_row in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719944</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.719827</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.687942</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.687648</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.658814</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.658439</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632006</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.631538</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607208</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.606595</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.584132</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.583390</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.562631</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.561719</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.542660</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.541553</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.523843</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.522582</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.506304</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.504898</td>\n",
       "      <td>0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.490148</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.474932</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.473150</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.460882</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.458933</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.447606</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.445515</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.435413</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.433145</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.424015</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.421570</td>\n",
       "      <td>0.000601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.413535</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.410915</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.403753</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.400974</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.394571</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.391619</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.386093</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.382983</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.378352</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.375099</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.370938</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.367507</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.364073</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.360522</td>\n",
       "      <td>0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.357688</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.353956</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.351825</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.347939</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.346178</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.342162</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.341073</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.336901</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.336238</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.331937</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.331763</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.327329</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.327789</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.323178</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>0.222877</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.158828</td>\n",
       "      <td>0.001332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.158775</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.222861</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.158725</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.222869</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.158638</td>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.222878</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.001355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.222877</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.158541</td>\n",
       "      <td>0.001357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.222865</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.158465</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.222864</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.158420</td>\n",
       "      <td>0.001377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.222851</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.158356</td>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.222850</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.158299</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.222838</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.158242</td>\n",
       "      <td>0.001367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.222841</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.158175</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>0.222841</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.158151</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.222849</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.158112</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.222840</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.158058</td>\n",
       "      <td>0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>0.222846</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.222830</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.157974</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.222829</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.157927</td>\n",
       "      <td>0.001414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0.222826</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.157863</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.222832</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.157819</td>\n",
       "      <td>0.001456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>0.222834</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.157782</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>0.222836</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.157726</td>\n",
       "      <td>0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.222833</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.157655</td>\n",
       "      <td>0.001444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.222839</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.157610</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.222827</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.157551</td>\n",
       "      <td>0.001444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.222834</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.157503</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.222832</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.157435</td>\n",
       "      <td>0.001476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.222833</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.157386</td>\n",
       "      <td>0.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.222832</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.157330</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.222835</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.157255</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0          0.719944       0.000537         0.719827        0.000239\n",
       "1          0.687942       0.000493         0.687648        0.000150\n",
       "2          0.658814       0.000404         0.658439        0.000109\n",
       "3          0.632006       0.000410         0.631538        0.000021\n",
       "4          0.607208       0.000402         0.606595        0.000113\n",
       "5          0.584132       0.000423         0.583390        0.000077\n",
       "6          0.562631       0.000524         0.561719        0.000097\n",
       "7          0.542660       0.000482         0.541553        0.000186\n",
       "8          0.523843       0.000508         0.522582        0.000327\n",
       "9          0.506304       0.000696         0.504898        0.000213\n",
       "10         0.490148       0.000881         0.488579        0.000145\n",
       "11         0.474932       0.000817         0.473150        0.000330\n",
       "12         0.460882       0.000806         0.458933        0.000354\n",
       "13         0.447606       0.001126         0.445515        0.000258\n",
       "14         0.435413       0.001133         0.433145        0.000429\n",
       "15         0.424015       0.001248         0.421570        0.000601\n",
       "16         0.413535       0.001248         0.410915        0.000573\n",
       "17         0.403753       0.001272         0.400974        0.000574\n",
       "18         0.394571       0.001227         0.391619        0.000552\n",
       "19         0.386093       0.001039         0.382983        0.000751\n",
       "20         0.378352       0.001048         0.375099        0.000790\n",
       "21         0.370938       0.001038         0.367507        0.000847\n",
       "22         0.364073       0.000834         0.360522        0.001110\n",
       "23         0.357688       0.001123         0.353956        0.000950\n",
       "24         0.351825       0.001060         0.347939        0.000934\n",
       "25         0.346178       0.001266         0.342162        0.000745\n",
       "26         0.341073       0.001545         0.336901        0.000484\n",
       "27         0.336238       0.001705         0.331937        0.000353\n",
       "28         0.331763       0.002014         0.327329        0.000102\n",
       "29         0.327789       0.001924         0.323178        0.000257\n",
       "..              ...            ...              ...             ...\n",
       "970        0.222877       0.001959         0.158828        0.001332\n",
       "971        0.222886       0.001958         0.158775        0.001326\n",
       "972        0.222861       0.001960         0.158725        0.001346\n",
       "973        0.222869       0.001956         0.158638        0.001355\n",
       "974        0.222878       0.001951         0.158600        0.001355\n",
       "975        0.222877       0.001950         0.158541        0.001357\n",
       "976        0.222865       0.001938         0.158465        0.001375\n",
       "977        0.222864       0.001952         0.158420        0.001377\n",
       "978        0.222851       0.001958         0.158356        0.001371\n",
       "979        0.222850       0.001953         0.158299        0.001368\n",
       "980        0.222838       0.001953         0.158242        0.001367\n",
       "981        0.222841       0.001963         0.158175        0.001373\n",
       "982        0.222841       0.001963         0.158151        0.001368\n",
       "983        0.222849       0.001963         0.158112        0.001358\n",
       "984        0.222840       0.001973         0.158058        0.001374\n",
       "985        0.222846       0.001970         0.158011        0.001385\n",
       "986        0.222830       0.001968         0.157974        0.001376\n",
       "987        0.222829       0.001960         0.157927        0.001414\n",
       "988        0.222826       0.001960         0.157863        0.001436\n",
       "989        0.222832       0.001961         0.157819        0.001456\n",
       "990        0.222834       0.001962         0.157782        0.001459\n",
       "991        0.222836       0.001969         0.157726        0.001448\n",
       "992        0.222833       0.001978         0.157655        0.001444\n",
       "993        0.222839       0.001958         0.157610        0.001461\n",
       "994        0.222827       0.001955         0.157551        0.001444\n",
       "995        0.222834       0.001951         0.157503        0.001437\n",
       "996        0.222832       0.001955         0.157435        0.001476\n",
       "997        0.222833       0.001971         0.157386        0.001473\n",
       "998        0.222832       0.001963         0.157330        0.001501\n",
       "999        0.222835       0.001976         0.157255        0.001497\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "xgb_params = {\n",
    "    'n_trees': 500,\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.7,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': 0.1,\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "# form DMatrices for Xgboost training\n",
    "dtrain = xgb.DMatrix(X, y[:, 0])\n",
    "\n",
    "num_boost_rounds = 1000\n",
    "#thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "\n",
    "#0.1930\n",
    "xgb.cv(xgb_params, dtrain, num_boost_round=num_boost_rounds,early_stopping_rounds=200)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = pd.DataFrame()\n",
    "subm['image_name'] = test_features.image_name.values\n",
    "subm['tags'] = preds\n",
    "subm.to_csv('submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}